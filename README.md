# GPT-2 学習履歴

## 概要
このリポジトリは、GPT-2に関する学習過程を記録したものです。日々の学習内容や実装内容を時系列で整理しています。

## プロジェクト構成
```
first_encounter_with_GPT-2/
└── Study_about_GPT-2/
```

---

# 学習履歴（更新済み）

## 2025/08/13 - 基本環境構築  
**Google Colab環境での基本セットアップ**

### 1. 環境設定
- 必要なPythonライブラリのインストール  
- GPU/CPU判定による最適化  
- 乱数シードの固定（結果の再現性確保）

### 2. モデル・トークナイザー詳細設定
- モデルサイズ選択  
- トークナイザー初期化（パディング設定含む）  
- 事前学習済みモデルのロード  
- デバイス転送 & パラメータ数確認

---

## 2025/08/14 - データセット構築  
**会話データセットの構築**

### 1. 会話データセットの設計
- `{"user": "ユーザー発話", "bot": "ボット応答"}`形式の辞書リスト

### 2. Excelマクロの作成（業務効率化）
- VBAマクロによるテンプレート自動化  
- セル指定による文の移動機能  
- 課題：1セル内に複数文を入れる処理が難航中

---

## 2025/08/15 - エラーハンドリング  
**エラー発生時の対応処理の設定**

### 1. 例外処理の実装
- 正常処理と例外処理の分離  
- 堅牢なコードベースの構築

---

## 2025/08/17 - データ前処理とコードレビュー  
**会話データを学習可能な形にする前処理**

### 1. データ前処理
- テキストのクリーニング  
- 特殊トークンによる構造化  
- バッチトークン化  
- Hugging Face Dataset形式への変換

### 2. 全体復習
- コードブロック1〜6の復習  
- 全体の流れと動作確認

---

## 2025/08/19 - tokenizer設定とコードブロック7  
**ChatBot制作時のtokenizerに必要な設定**

### 1. tokenizer設定
- `max_length`と`truncation`の指定  
- EOSをPADの代用として使用  
- 会話開始・終了用の特殊トークン作成

### 2. コードブロック7の内容
- `TrainingArguments`で学習パラメータ定義  
  - エポック数、バッチサイズ、勾配更新頻度、学習率（3e-5）  
- `DataCollator`で学習のまとめ方指定  
  - ステップごとの保存、検証無効化  
- 出力確認：エポック数、バッチサイズ、勾配累積、学習率、FP16など

---

# 学習統計（更新済み）

| 項目             | 詳細                             |
|------------------|----------------------------------|
| **開始日**       | 2025/08/13                       |
| **学習日数**     | 7日目（2025/08/19時点）         |
| **完了セクション**| 7                                |
| **主な成果**     | 環境構築、データ設計、前処理、tokenizer設定 |

---

**最終更新: 2025/08/19**
